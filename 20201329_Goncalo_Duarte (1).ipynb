{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the needed packages\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the dataset\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data.set_index('Guest_ID', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILL NA\n",
    "\n",
    "data2=data.copy()\n",
    "data2.dropna(axis=0, inplace=True)\n",
    "data2['Age']=data2['Date_Birth'].apply(lambda x: x[-4:])\n",
    "data2['Age']=2021-pd.to_numeric(data2['Age'])\n",
    "age_mean=data2['Age'].mean()\n",
    "\n",
    "age_temporary = \"2021\"\n",
    "data['Date_Birth'].fillna(age_temporary, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURE ENG\n",
    "\n",
    "data['Age']=data['Date_Birth'].apply(lambda x: x[-4:]) \n",
    "data['Age']=2021-pd.to_numeric(data['Age'])\n",
    "data.drop(columns=['Date_Birth'], inplace=True)\n",
    "\n",
    "## FIX NA\n",
    "data[\"Age\"].replace({0: age_mean}, inplace=True)\n",
    "\n",
    "new = data['Name'].str.split(\" \", n = 2, expand = True) \n",
    "data['Gender']= new[0] \n",
    "data.loc[data.Gender==\"Mr.\",\"Gender\"]=\"M\"\n",
    "data.loc[data.Gender==\"Mrs.\",\"Gender\"]=\"F\"\n",
    "data.loc[data.Gender==\"Miss\",\"Gender\"]=\"F\"\n",
    "data['Gender'] = np.where((data['Gender']=='M'),1,0)\n",
    "data.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "data['Flight_Class_2'] = data['Flight_Class']\n",
    "data['Flight_Class_2'].replace('Eco Plus', 'Eco',inplace=True)\n",
    "\n",
    "data['Points/Age']=data['Points']/data['Age']\n",
    "\n",
    "data['AVG_Score1']=data[['Room','Check-in/Check-out','F&B','Location','Wifi','Entertainment','Gym','Spa','Staff','Pool','Baggage_Handling','Reception','Cleanliness','Online_Booking']].sum(axis=1)\n",
    "data['AVG_Score2']=data[['Room','Check-in/Check-out','F&B','Location','Wifi','Entertainment','Cleanliness']].sum(axis=1)\n",
    "data['AVG_Score3']=data[['Room','F&B','Cleanliness','Location']].sum(axis=1)\n",
    "data['AVG_Score4']=data[['Wifi','Entertainment','Gym','Spa','Pool']].sum(axis=1)\n",
    "data['AVG_Score5']=data[['Staff','Baggage_Handling','Reception']].sum(axis=1)\n",
    "data['AVG_Score6']=data[['Check-in/Check-out','Online_Booking']].sum(axis=1)\n",
    "\n",
    "data=pd.get_dummies(data)\n",
    "data.drop(columns=['Type_Personal Travel','Flight_Class_2_Eco','Flight_Class_Eco'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(data, model):\n",
    "    # apply StratifiedK-Fold\n",
    "    skf = StratifiedKFold(n_splits = 10)\n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    X = data.drop(columns=['Repeater'])\n",
    "    y = data['Repeater'].copy()\n",
    "    score_train = []\n",
    "    score_val = []\n",
    "    for train_index, val_index in skf.split(X,y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "               \n",
    "        # This time we are going to use validation to check overfitting \n",
    "        # so we need also to make all the needed changes in the validation\n",
    "        \n",
    "        # Apply model\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions_train = model.predict(X_train)\n",
    "        predictions_val = model.predict(X_val)\n",
    "        score_train.append(f1_score(y_train, predictions_train))\n",
    "        score_val.append(f1_score(y_val, predictions_val))\n",
    "\n",
    "        avg_train = round(np.mean(score_train),5)\n",
    "        avg_val = round(np.mean(score_val),5)\n",
    "        std_train = round(np.std(score_train),5)\n",
    "        std_val = round(np.std(score_val),5)\n",
    "\n",
    "    return str(avg_train) + '+/-' + str(std_train),str(avg_val) + '+/-' + str(std_val)\n",
    "    \n",
    "def show_results(df, data, *args):\n",
    "    \"\"\"\n",
    "    Receive an empty dataframe and the different models and call the function avg_score\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # for each model passed as argument\n",
    "    for arg in args:\n",
    "        # obtain the results provided by avg_score\n",
    "        avg_train, avg_test = compare_models(data, arg)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = avg_train, avg_test\n",
    "        count+=1\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CF</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.95032+/-0.0062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Train        Validation\n",
       "CF  1.0+/-0.0  0.95032+/-0.0062"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## BEST MODEL USING CROSS VALIDATION\n",
    "\n",
    "modelCF = GradientBoostingClassifier(random_state=5,loss='deviance', learning_rate=0.2, n_estimators=900, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=7, min_impurity_decrease=0.0, min_impurity_split=None, init=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "\n",
    "df = pd.DataFrame(columns = ['Train','Validation'], index = ['CF'])\n",
    "show_results(df, data, modelCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, max_depth=7, n_estimators=900,\n",
       "                           random_state=5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CREATE OPTIMAL MODEL USING ALL DATA\n",
    "\n",
    "X = data.drop(columns=['Repeater'])\n",
    "y = data['Repeater'].copy()\n",
    "\n",
    "final_model = GradientBoostingClassifier(random_state=5,loss='deviance', learning_rate=0.2, n_estimators=900, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=7, min_impurity_decrease=0.0, min_impurity_split=None, init=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PERFORMANCE OPTIMAL MODEL ON ALL TRAINING DATA\n",
    "\n",
    "final_model.fit(X, y)\n",
    "predictions_train = final_model.predict(X)\n",
    "f1_score(y, predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT TEST DATASET\n",
    "\n",
    "data_test = pd.read_csv('test.csv')\n",
    "data_test.set_index('Guest_ID', inplace = True)\n",
    "\n",
    "## FEATURE ENG\n",
    "\n",
    "data2_test=data_test.copy()\n",
    "data2_test.dropna(inplace=True)\n",
    "data2_test['Age']=data2_test['Date_Birth'].apply(lambda x: x[-4:])\n",
    "data2_test['Age']=2021-pd.to_numeric(data2_test['Age'])\n",
    "age_mean_test=data2_test['Age'].mean()\n",
    "\n",
    "age_temporary = \"2021\"\n",
    "data_test['Date_Birth'].fillna(age_temporary, inplace = True)\n",
    "data_test['Age']=data_test['Date_Birth'].apply(lambda x: x[-4:]) \n",
    "data_test['Age']=2021-pd.to_numeric(data_test['Age'])\n",
    "data_test.drop(columns=['Date_Birth'], inplace=True)\n",
    "\n",
    "## FIX NA\n",
    "data_test[\"Age\"].replace({0: age_mean_test}, inplace=True)\n",
    "\n",
    "new = data_test['Name'].str.split(\" \", n = 2, expand = True) \n",
    "data_test['Gender']= new[0] \n",
    "data_test.loc[data_test.Gender==\"Mr.\",\"Gender\"]=\"M\"\n",
    "data_test.loc[data_test.Gender==\"Mrs.\",\"Gender\"]=\"F\"\n",
    "data_test.loc[data_test.Gender==\"Miss\",\"Gender\"]=\"F\"\n",
    "data_test['Gender'] = np.where((data_test['Gender']=='M'),1,0)\n",
    "data_test.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "data_test['Flight_Class_2'] = data_test['Flight_Class']\n",
    "data_test['Flight_Class_2'].replace('Eco Plus', 'Eco',inplace=True)\n",
    "\n",
    "data_test['Points/Age']=data_test['Points']/data_test['Age']\n",
    "\n",
    "data_test['AVG_Score1']=data_test[['Room','Check-in/Check-out','F&B','Location','Wifi','Entertainment','Gym','Spa','Staff','Pool','Baggage_Handling','Reception','Cleanliness','Online_Booking']].sum(axis=1)\n",
    "data_test['AVG_Score2']=data_test[['Room','Check-in/Check-out','F&B','Location','Wifi','Entertainment','Cleanliness']].sum(axis=1)\n",
    "data_test['AVG_Score3']=data_test[['Room','F&B','Cleanliness','Location']].sum(axis=1)\n",
    "data_test['AVG_Score4']=data_test[['Wifi','Entertainment','Gym','Spa','Pool']].sum(axis=1)\n",
    "data_test['AVG_Score5']=data_test[['Staff','Baggage_Handling','Reception']].sum(axis=1)\n",
    "data_test['AVG_Score6']=data_test[['Check-in/Check-out','Online_Booking']].sum(axis=1)\n",
    "\n",
    "data_test=pd.get_dummies(data_test)\n",
    "data_test.drop(columns=['Type_Personal Travel','Flight_Class_2_Eco','Flight_Class_Eco'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Repeater'] = final_model.predict(data_test)\n",
    "final_csv = data_test['Repeater'].copy()\n",
    "final_csv.to_csv('result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
